{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.11.1 soupsieve-2.3.2.post1\n"
     ]
    }
   ],
   "source": [
    "#!pip install beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # Импортируем библиотеку BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем извлекать данные из любой веб-страницы.\n",
    "\n",
    "Ранее мы уже получили содержимое страницы с помощью GET-запроса и сохранили информацию в переменной response , теперь создадим объект BeautifulSoup с именем page, указывая в качестве параметра html.parser.\n",
    "\n",
    "Для примера получим информацию o title (с англ. заголовок) — это строка, которая отображается на вкладке браузера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей</title>\n",
      "Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей\n"
     ]
    }
   ],
   "source": [
    "import requests # Импортируем библиотеку requests\n",
    "from bs4 import BeautifulSoup # Импортируем библиотеку BeautifulSoup\n",
    "url = 'https://nplus1.ru/news/2021/10/11/econobel2021' # Определяем адрес страницы\n",
    "response = requests.get(url) # Выполняем GET-запрос, содержимое ответа присваивается переменной response\n",
    "page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup, указывая html-парсер\n",
    "print(page.title) # Получаем тег title, отображающийся на вкладке браузера\n",
    "print(page.title.text) # Выводим текст из полученного тега, который содержится в атрибуте text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним поставленную ранее задачу: получить информацию о [странице](https://nplus1.ru/news/2021/10/11/econobel2021) и извлечь заголовок статьи, опубликованной на этой странице, дату публикации, а также текст статьи.\n",
    "\n",
    "Предположим, что мы знаем, что в HTML-коде рассматриваемой нами страницы заголовок статьи заключён в тег < h1 > … < /h1 > (заголовок первого уровня).\n",
    "\n",
    "Тогда мы можем получить его текст с помощью метода find() (с англ. найти) объекта BeautifulSoup, передав ему название интересующего нас тега:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "print(page.find('h1').text) # Применяем метод find() к объекту и выводим результат на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проще всего это сделать с помощью так называемого __инструмента разработчика__(F12), который есть во всех современных браузерах. Покажем, как открыть данный инструмент на примере использования браузера Google Chrome.\n",
    "\n",
    "Устанавливаем курсор на элементе страницы (заголовок статьи), информацию о котором хотим получить, нажимаем на правую клавишу мыши и в выпадающем списке выбираем пункт «Просмотреть код элемента» или «Посмотреть код» в зависимости от браузера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13:04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(page.find('span').text) # Выводим на экран содержимое атрибута text тега span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Неуникальные теги: извлекаем текст статьи </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дело в том, что теги < span> … < /span> очень распространённые и на странице их очень много. Метод find() нашёл первый из них, но это не то, что нам надо.\n",
    "\n",
    "Посмотрим на нашу страницу, используя инструмент разработчика, ещё раз. Можем заметить, что у искомого текста есть свой класс — \"mw-page-title-main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operating system'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wiki_header(url):\n",
    "    response = requests.get(url) # Выполняем GET-запрос, содержимое ответа присваивается переменной response\n",
    "    page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup, указывая html-парсер\n",
    "    return(page.find('span', class_=\"mw-page-title-main\").text)\n",
    "    \n",
    "wiki_header('https://en.wikipedia.org/wiki/Operating_system')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Сбор нескольких элементов: собираем все ссылки на странице </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что все названия языков программирования на этой странице связаны ссылками c соответствующими статьями о них. Таким образом, нам необходимо собрать все ссылки на странице. \n",
    "\n",
    "Для ссылок в HTML предусмотрен тег < a> … < /a>. Попробуем использовать find():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"mw-jump-link\" href=\"#bodyContent\">Jump to content</a>\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_programming_languages' # Задаём адрес ресурса\n",
    "response = requests.get(url) # Делаем GET-запрос к ресурсу\n",
    "page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup\n",
    "print(page.find('a')) # Ищем ссылку по тегу <a> и выводим её на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили только одну ссылку, хотя на странице их явно больше.\n",
    "\n",
    "Это происходит, потому что метод find() возвращает только первый подходящий элемент. Если требуется получить больше элементов, необходимо воспользоваться методом find_all() (с англ. найти все):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950\n"
     ]
    }
   ],
   "source": [
    "links = page.find_all('a') # Ищем все ссылки на странице и сохраняем в переменной links в виде списка\n",
    "print(len(links)) # Выводим количество найденных ссылок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Magik', 'Magma', 'Máni', 'Maple', 'MAPPER', 'MARK-IV', 'Mary', 'MATLAB', 'MASM Microsoft Assembly x86', 'MATH-MATIC']\n"
     ]
    }
   ],
   "source": [
    "print([link.text for link in links[500:510]]) # Выводим ссылки с 500 по 509 включительно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jump to content', '\\n\\n\\n\\n\\n\\n', '\\nSearch\\n', 'Create account', 'Create account', 'Log in', 'learn more', 'Talk', 'Contributions', 'Main page']\n"
     ]
    }
   ],
   "source": [
    "print([link.text for link in links[0:10]]) # Выводим ссылки с 1 по 9 включительно"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
